{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachin/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('./data/**/*.npy')\n",
    "im_files = glob.glob('./data/**/*.png')\n",
    "labels = [f.split('/')[2] for f in files]\n",
    "\n",
    "u_labels = set(labels)\n",
    "label_dict = dict(zip(u_labels, range(len(u_labels))))\n",
    "reverse_dict = dict(zip(label_dict.values(), label_dict.keys()))\n",
    "num_labels = [label_dict[l] for l in labels]\n",
    "\n",
    "num_labels = np.array(num_labels)\n",
    "labels = np.array(labels)\n",
    "len_data = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.zeros((len_data, 80, 80, 3), dtype=np.int32)\n",
    "for i, f in enumerate(im_files):\n",
    "    images[i] = cv2.resize(cv2.imread(f), (80, 80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label imbalance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('George_W_Bush', 530),\n",
       " ('Colin_Powell', 236),\n",
       " ('Tony_Blair', 144),\n",
       " ('Donald_Rumsfeld', 121),\n",
       " ('Gerhard_Schroeder', 109),\n",
       " ('Ariel_Sharon', 77),\n",
       " ('Hugo_Chavez', 71),\n",
       " ('Junichiro_Koizumi', 60),\n",
       " ('Jean_Chretien', 55),\n",
       " ('John_Ashcroft', 53)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10 = Counter(labels).most_common()[:10]\n",
    "top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4324, 128)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = []\n",
    "for f in files:\n",
    "    embeds.append(np.load(f))\n",
    "embeds = np.array(embeds)\n",
    "embeds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embeds seem to be all unit vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9999999 , 0.99999994, 1.        , ..., 1.0000001 , 1.        ,\n",
       "       1.        ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.square(embeds),axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Cosine Distance to determine closest face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_dist(query, db, nlargest=5):\n",
    "    cosine_dist = db.dot(query)\n",
    "    ind = np.argpartition(cosine_dist, -nlargest)[-nlargest:]\n",
    "    ind = ind[np.argsort(-cosine_dist[ind])]\n",
    "    return ind, cosine_dist[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest to Hugo_Chavez is:\n",
      "['Gerhard_Schroeder' 'Hugo_Chavez' 'Adrien_Brody' 'Bill_McBride']\n",
      "[0.9735214  0.97274005 0.9726215  0.97176164] \n",
      "\n",
      "Closest to Hillary_Clinton is:\n",
      "['Laura_Bush' 'Gerhard_Schroeder' 'Hugo_Chavez' 'Laura_Bush']\n",
      "[0.97384155 0.9707303  0.9704779  0.9702305 ] \n",
      "\n",
      "Closest to Jack_Straw is:\n",
      "['Donald_Rumsfeld' 'Colin_Powell' 'George_W_Bush' 'Howard_Dean']\n",
      "[0.9758383 0.9739548 0.973784  0.9730892] \n",
      "\n",
      "Closest to Tony_Blair is:\n",
      "['Colin_Powell' 'Tony_Blair' 'Trent_Lott' 'Colin_Powell']\n",
      "[0.97413075 0.9732443  0.9713545  0.9704548 ] \n",
      "\n",
      "Closest to Gerhard_Schroeder is:\n",
      "['Hugo_Chavez' 'Keanu_Reeves' 'Jose_Maria_Aznar' 'Gerhard_Schroeder']\n",
      "[0.9805705 0.9779444 0.9772387 0.9769714] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.choice(len(labels), 5, replace=False):\n",
    "    print('Closest to', labels[i], 'is:')\n",
    "    ind, dist = min_dist(embeds[i], embeds)\n",
    "    print(labels[ind][1:])\n",
    "    print(dist[1:],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing FaceNet with triplet loss \n",
    "We will implement facenet with current embeddings. PCA gives an idea about layer width to preserve information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24855697, 0.37725508, 0.4705602 , 0.5535307 , 0.61517996,\n",
       "       0.65303725, 0.6895475 , 0.7174537 , 0.74171203, 0.7629557 ,\n",
       "       0.78303856, 0.7992914 , 0.8131017 , 0.8260136 , 0.8371492 ,\n",
       "       0.8476178 , 0.8576322 , 0.8666004 , 0.8754376 , 0.8837001 ,\n",
       "       0.89065534, 0.89678925, 0.9028618 , 0.9088181 , 0.9143214 ,\n",
       "       0.9195691 , 0.92445004, 0.92906505, 0.9332311 , 0.9372343 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=30)\n",
    "pca.fit(embeds)\n",
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(len(labels)*0.8)\n",
    "missing_in_test = set([1])\n",
    "# while loop is to ensure that test set has all its labels in train set\n",
    "while len(missing_in_test) != 0:\n",
    "    idx = np.random.permutation(len(labels))\n",
    "    train_idx = idx[:train_len]\n",
    "    test_idx = idx[train_len:]\n",
    "    \n",
    "    train_labels = num_labels[train_idx]\n",
    "    test_labels = num_labels[test_idx]\n",
    "    \n",
    "    train_embeds = embeds[train_idx]\n",
    "    test_embeds = embeds[test_idx]\n",
    "    \n",
    "    missing_in_test = set(test_labels) - set(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a balanced dataset for training by resampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeat = 50\n",
    "u_train_labels = np.unique(train_labels)\n",
    "\n",
    "train_embeds2 = np.zeros((n_repeat*len(u_train_labels), train_embeds.shape[1]))\n",
    "train_labels2 = np.zeros(n_repeat*len(u_train_labels), dtype=np.int32)\n",
    "for i,l in enumerate(u_train_labels):\n",
    "    idx = np.random.choice(np.where(train_labels==l)[0], n_repeat)\n",
    "    train_embeds2[i*n_repeat:(i+1)*n_repeat,:] = train_embeds[idx]\n",
    "    train_labels2[i*n_repeat:(i+1)*n_repeat] = train_labels[idx]\n",
    "idx = np.random.permutation(len(train_embeds2))\n",
    "train_embeds = train_embeds2[idx]\n",
    "train_labels = train_labels2[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = StandardScaler()\n",
    "train_embeds = x_scaler.fit_transform(train_embeds)\n",
    "test_embeds = x_scaler.transform(test_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachin/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:97: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "alpha = 0.3\n",
    "d = 128\n",
    "with graph.as_default():\n",
    "    xs = tf.placeholder(tf.float32, shape=(None, d))\n",
    "    a = tf.placeholder(tf.int32, shape=(None,))\n",
    "    p = tf.placeholder(tf.int32, shape=(None,))\n",
    "    n = tf.placeholder(tf.int32, shape=(None,))\n",
    "    \n",
    "    with tf.name_scope('mlp'):\n",
    "        h1 = tf.layers.dense(inputs=xs, units=15, activation=tf.nn.relu,\n",
    "                             name='h1')\n",
    "        out = tf.layers.dense(h1, units=15, name='out')\n",
    "    \n",
    "    # convert to unit length\n",
    "    len_out = tf.sqrt(tf.reduce_sum(tf.square(out), axis=-1, keepdims=True))\n",
    "    out = out / len_out\n",
    "    \n",
    "    out_a = tf.gather(out, a)\n",
    "    out_p = tf.gather(out, p)\n",
    "    out_n = tf.gather(out, n)\n",
    "    \n",
    "    # triplet loss\n",
    "    with tf.name_scope('loss'):\n",
    "        pos_dist = tf.reduce_sum(tf.square(out_a - out_p), axis=-1)\n",
    "        neg_dist = tf.reduce_sum(tf.square(out_a - out_n), axis=-1)\n",
    "        basic_loss = pos_dist - neg_dist + alpha\n",
    "        loss = tf.reduce_mean(tf.nn.relu(basic_loss))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(embeds, start = 0, batch_size=64):\n",
    "    \"\"\"\n",
    "    Takes the starting position of anchors (and corresponding batchsize) to find positive examples and negative. \n",
    "    Positives are furthest ones away from anchor embeddings and negatives are closest to anchors.\n",
    "    Returns the indices of anchors, positive and negative exemplars.\n",
    "    \"\"\"\n",
    "    stop = start + batch_size\n",
    "    anchors = new_embeds[start:stop]\n",
    "    # cosine distance (not similarity)\n",
    "    dist = -new_embeds.dot(anchors.T)\n",
    "    pos_label = np.zeros(dist.shape[1], dtype=np.int32) - 1\n",
    "    neg_label = np.zeros(dist.shape[1], dtype=np.int32) - 1\n",
    "    invalids = []\n",
    "    for i in range(dist.shape[1]):\n",
    "        current_class = train_labels[start + i]\n",
    "        \n",
    "        pos_classes = np.where(train_labels==current_class)[0]\n",
    "        pos_label[i] = pos_classes[np.argmax(dist[pos_classes,i])]\n",
    "        neg_label[i] = np.random.choice(np.where(train_labels!=current_class)[0])\n",
    "#         min_dist = np.inf\n",
    "#         max_dist = -np.inf\n",
    "#         for j in range(dist.shape[0]):\n",
    "#             if i == j:\n",
    "#                 continue\n",
    "#             # find positives\n",
    "#             if train_labels[j] == current_class:\n",
    "#                 if dist[j, i] > max_dist:\n",
    "#                     max_dist = dist[j, i]\n",
    "#                     pos_label[i] = j\n",
    "#             else:\n",
    "#                 if dist[j, i] < min_dist:\n",
    "#                     min_dist = dist[j, i]\n",
    "#                     neg_label[i] = j\n",
    "        if pos_label[i] == -1 or neg_label[i] == -1:\n",
    "            invalids.append(i)\n",
    "\n",
    "    anchors = np.arange(start, start+i+1)\n",
    "    if invalids:\n",
    "        anchors = np.delete(anchors, invalids)\n",
    "        pos_label =  np.delete(pos_label, invalids)\n",
    "        neg_label = np.delete(neg_label, invalids)\n",
    "    \n",
    "    return anchors, pos_label, neg_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "losses = []\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(epochs):\n",
    "        for start in range(0, len(train_embeds), batch_size):\n",
    "            feed_dict = {xs: train_embeds}\n",
    "            new_embeds = session.run(out, feed_dict=feed_dict)\n",
    "            anchors, pos_label, neg_label = get_batch(new_embeds, start, \n",
    "                                                      batch_size)\n",
    "#             break\n",
    "            \n",
    "            feed_dict = {xs: train_embeds, \n",
    "                         a: anchors, \n",
    "                         p:pos_label, \n",
    "                         n:neg_label}\n",
    "            _, loss_ = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "            losses.append(loss_)\n",
    "            \n",
    "    \n",
    "    feed_dict = {xs: test_embeds}\n",
    "    new_test_embeds = session.run(out, feed_dict=feed_dict)\n",
    "    feed_dict = {xs: embeds}\n",
    "    final_embeds = session.run(out, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a327bcb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.savefig('losses.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest to Lindsay_Davenport is:\n",
      "['Alejandro_Toledo', 'Jennifer_Garner', 'Jose_Maria_Aznar', 'Tim_Henman']\n",
      "[0.980266   0.97844666 0.9638734  0.960642  ] \n",
      "\n",
      "Closest to Donald_Rumsfeld is:\n",
      "['Hillary_Clinton', 'Gloria_Macapagal_Arroyo', 'Lleyton_Hewitt', 'Naomi_Watts']\n",
      "[0.99121505 0.98923516 0.98859507 0.9883354 ] \n",
      "\n",
      "Closest to Colin_Powell is:\n",
      "['Junichiro_Koizumi', 'Jacques_Rogge', 'Condoleezza_Rice', 'Colin_Powell']\n",
      "[0.99445724 0.9944418  0.9928882  0.99202913] \n",
      "\n",
      "Closest to Jack_Straw is:\n",
      "['David_Beckham', 'Hamid_Karzai', 'Jack_Straw', 'Vladimir_Putin']\n",
      "[0.9969831 0.9953164 0.9952843 0.99514  ] \n",
      "\n",
      "Closest to John_Paul_II is:\n",
      "['George_W_Bush', 'Gray_Davis', 'Luiz_Inacio_Lula_da_Silva', 'George_W_Bush']\n",
      "[0.9945506  0.994079   0.9932676  0.99190307] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.choice(len(test_labels), 5, replace=False):\n",
    "    print('Closest to', reverse_dict[test_labels[i]], 'is:')\n",
    "    ind, dist = min_dist(new_test_embeds[i], new_test_embeds)\n",
    "    print([reverse_dict[i] for i in test_labels[ind][1:]])\n",
    "    print(dist[1:],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest to Keanu_Reeves is:\n",
      "['Paradorn_Srichaphan' 'Salma_Hayek' 'Gerhard_Schroeder' 'Sergey_Lavrov']\n",
      "[0.99993956 0.9998925  0.99989116 0.9998869 ] \n",
      "\n",
      "Closest to Tony_Blair is:\n",
      "['Gloria_Macapagal_Arroyo' 'Salma_Hayek' 'Jose_Maria_Aznar'\n",
      " 'Gloria_Macapagal_Arroyo']\n",
      "[0.9999182  0.9999097  0.9999022  0.99989665] \n",
      "\n",
      "Closest to Gerhard_Schroeder is:\n",
      "['Gerhard_Schroeder' 'Spencer_Abraham' 'Alejandro_Toledo'\n",
      " 'Gerhard_Schroeder']\n",
      "[0.9999023  0.999899   0.9998952  0.99989116] \n",
      "\n",
      "Closest to Colin_Powell is:\n",
      "['Colin_Powell' 'Mahmoud_Abbas' 'Tom_Daschle' 'Colin_Powell']\n",
      "[0.99992126 0.9999131  0.99991155 0.9999111 ] \n",
      "\n",
      "Closest to John_Negroponte is:\n",
      "['Jennifer_Lopez' 'Meryl_Streep' 'Donald_Rumsfeld' 'Jennifer_Lopez']\n",
      "[0.99994653 0.99994564 0.9999399  0.99993503] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.choice(len(labels), 5, replace=False):\n",
    "    print('Closest to', labels[i], 'is:')\n",
    "    ind, dist = min_dist(final_embeds[i], final_embeds)\n",
    "    print(labels[ind][1:])\n",
    "    print(dist[1:],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen below the algorithm has not worked. Even the furthest vector has a similarity of 0.99+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99514586"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeds.dot(final_embeds[i]).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using KNN on original embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "train_embeds = x_scaler.inverse_transform(train_embeds)\n",
    "test_embeds = x_scaler.inverse_transform(test_embeds)\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(train_embeds, train_labels) \n",
    "\n",
    "pred_labels = neigh.predict(test_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN achieves higher accuracy than the more complicated Keras Model in other Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07052023121387284"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pred_labels == test_labels)/len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
