{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachin/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import callbacks\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('./data/**/*.npy')\n",
    "im_files = glob.glob('./data/**/*.png')\n",
    "labels = [f.split('/')[2] for f in files]\n",
    "\n",
    "u_labels = set(labels)\n",
    "label_dict = dict(zip(u_labels, range(len(u_labels))))\n",
    "reverse_dict = dict(zip(label_dict.values(), label_dict.keys()))\n",
    "num_labels = [label_dict[l] for l in labels]\n",
    "\n",
    "num_labels = np.array(num_labels)\n",
    "labels = np.array(labels)\n",
    "len_data = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label imbalance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('George_W_Bush', 530),\n",
       " ('Colin_Powell', 236),\n",
       " ('Tony_Blair', 144),\n",
       " ('Donald_Rumsfeld', 121),\n",
       " ('Gerhard_Schroeder', 109),\n",
       " ('Ariel_Sharon', 77),\n",
       " ('Hugo_Chavez', 71),\n",
       " ('Junichiro_Koizumi', 60),\n",
       " ('Jean_Chretien', 55),\n",
       " ('John_Ashcroft', 53)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10 = Counter(labels).most_common()[:10]\n",
    "top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4324, 128)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = []\n",
    "for f in files:\n",
    "    embeds.append(np.load(f))\n",
    "embeds = np.array(embeds)\n",
    "embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(len(labels)*0.8)\n",
    "missing_in_test = set([1])\n",
    "# while loop is to ensure that test set has all its labels in train set\n",
    "while len(missing_in_test) != 0:\n",
    "    idx = np.random.permutation(len(labels))\n",
    "    train_idx = idx[:train_len]\n",
    "    test_idx = idx[train_len:]\n",
    "    \n",
    "    train_labels = num_labels[train_idx]\n",
    "    test_labels = num_labels[test_idx]\n",
    "    \n",
    "    train_embeds = embeds[train_idx]\n",
    "    test_embeds = embeds[test_idx]\n",
    "    \n",
    "    missing_in_test = set(test_labels) - set(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a balanced dataset by resampling all classes 50 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeat = 50\n",
    "u_train_labels = np.unique(train_labels)\n",
    "\n",
    "train_embeds2 = np.zeros((n_repeat*len(u_train_labels), train_embeds.shape[1]))\n",
    "train_labels2 = np.zeros(n_repeat*len(u_train_labels), dtype=np.int32)\n",
    "for i,l in enumerate(u_train_labels):\n",
    "    idx = np.random.choice(np.where(train_labels==l)[0], n_repeat)\n",
    "    train_embeds2[i*n_repeat:(i+1)*n_repeat,:] = train_embeds[idx]\n",
    "    train_labels2[i*n_repeat:(i+1)*n_repeat] = train_labels[idx]\n",
    "idx = np.random.permutation(len(train_embeds2))\n",
    "train_embeds = train_embeds2[idx]\n",
    "train_labels = train_labels2[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sachin/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/sachin/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1204: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 158)               1738      \n",
      "=================================================================\n",
      "Total params: 3,138\n",
      "Trainable params: 3,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation='relu', input_dim=train_embeds.shape[1]))\n",
    "model.add(Dense(units=10, activation='relu'))\n",
    "model.add(Dense(units=len(u_train_labels), activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18188ab240>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 128\n",
    "cb_list = [\n",
    "            callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=1,\n",
    "                min_lr=1e-9\n",
    "            )\n",
    "    ]\n",
    "model.fit(train_embeds, train_labels, batch_size=batch_size, epochs=epochs, verbose=0, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7900/7900 [==============================] - 0s 27us/step\n",
      "[3.7107421336596524, 0.1303797468411017]\n",
      "865/865 [==============================] - 0s 27us/step\n",
      "[4.219648952153377, 0.06127167630057803]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(train_embeds, train_labels))\n",
    "print(model.evaluate(test_embeds, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is still better than random (0.04 > 1/158). The other reason its doing much better than test set is most likely due to the fact that its learning to classify one class better than the other. There is a class imbalance in test set since I did not resample the test_labels. As seen below the resampled version has an improved accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeat = 50\n",
    "u_test_labels = np.unique(test_labels)\n",
    "\n",
    "test_embeds2 = np.zeros((n_repeat*len(u_test_labels), test_embeds.shape[1]))\n",
    "test_labels2 = np.zeros(n_repeat*len(u_test_labels), dtype=np.int32)\n",
    "for i,l in enumerate(u_test_labels):\n",
    "    idx = np.random.choice(np.where(test_labels==l)[0], n_repeat)\n",
    "    test_embeds2[i*n_repeat:(i+1)*n_repeat,:] = test_embeds[idx]\n",
    "    test_labels2[i*n_repeat:(i+1)*n_repeat] = test_labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7600/7600 [==============================] - 0s 25us/step\n",
      "[4.368647848430433, 0.06394736842105263]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(test_embeds2, test_labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
